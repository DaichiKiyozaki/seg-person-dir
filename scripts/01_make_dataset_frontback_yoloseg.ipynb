{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15b25a72",
   "metadata": {},
   "source": [
    "# 01_make_dataset_frontback_yoloseg - データセット生成ノートブック\n",
    "\n",
    "## 概要\n",
    "YOLO-Segをファインチューニングする用のデータセットを生成\n",
    "\n",
    "## 処理フロー（概要）\n",
    "1. COCOアノテーション読み込み\n",
    "2. **キーポイントゲート（IDレベル）**：全身が十分に映っている歩行者がいる画像のみ抽出\n",
    "3. ゲート通過IDから `train` / `test` / `val` を作成（画像はまだダウンロードしない）\n",
    "4. 通過画像のみダウンロード\n",
    "5. MEBOWで向き推定 → SAME/OPS分類\n",
    "6. COCOセグメンテーション → YOLO-Seg形式ラベル（ポリゴン）へ変換・エクスポート\n",
    "7. `data.yaml` 生成\n",
    "\n",
    "## クラス定義\n",
    "- `0: SAME`：カメラと同方向（角度 $\\le 45^\\circ$ または $\\ge 315^\\circ$）\n",
    "- `1: OPS`：それ以外（逆方向）\n",
    "\n",
    "## キーポイントゲート\n",
    "- 必須：両肩・両ひざ（可視性 $v \\ge 1$）\n",
    "- 画像内に **1人でも** 条件を満たす歩行者がいれば → その画像の全personをラベル化\n",
    "- 誰も満たさなければ → 画像はダウンロードせずスキップ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbca35f7",
   "metadata": {},
   "source": [
    "## 1. 環境確認とパス設定\n",
    "\n",
    "プロジェクトルートパスを設定し、GPU利用可否を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb154fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# パス設定と環境確認\n",
    "# ============================================================================\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# ----- プロジェクトルートの設定 -----\n",
    "# scripts/ から1つ上のディレクトリがプロジェクトルート\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "print(f\"PROJECT_ROOT: {PROJECT_ROOT}\")\n",
    "\n",
    "# ----- 各ディレクトリパスの定義 -----\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "DATA_RAW = DATA_DIR / \"raw\"                           # COCO画像DL先\n",
    "DATA_OUT = DATA_DIR / \"dataset_frontback_yoloseg\"     # 出力先\n",
    "\n",
    "# COCOアノテーション\n",
    "COCO_ANN_DIR = DATA_DIR / \"annotations\"\n",
    "ANN_TRAIN = COCO_ANN_DIR / \"instances_train2017.json\"\n",
    "ANN_VAL   = COCO_ANN_DIR / \"instances_val2017.json\"\n",
    "\n",
    "# COCOキーポイント（ノイズフィルタ用）\n",
    "KP_TRAIN = COCO_ANN_DIR / \"person_keypoints_train2017.json\"\n",
    "KP_VAL   = COCO_ANN_DIR / \"person_keypoints_val2017.json\"\n",
    "\n",
    "# MEBOWモデル（同一リポジトリ配下）\n",
    "MEBOW_ROOT = PROJECT_ROOT / \"MEBOW\"\n",
    "MEBOW_WEIGHT = MEBOW_ROOT / \"models\" / \"model_hboe.pth\"\n",
    "\n",
    "print(f\"  DATA_RAW: {DATA_RAW}\")\n",
    "print(f\"  DATA_OUT: {DATA_OUT}\")\n",
    "print(f\"  COCO_ANN_DIR: {COCO_ANN_DIR}\")\n",
    "print(f\"  MEBOW_ROOT: {MEBOW_ROOT}\")\n",
    "\n",
    "# ----- GPU確認 -----\n",
    "import torch\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f12746d",
   "metadata": {},
   "source": [
    "## 2. ディレクトリ構造の作成\n",
    "\n",
    "YOLO学習に必要なディレクトリ構造を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34366d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ディレクトリ構造の作成\n",
    "# ============================================================================\n",
    "# \n",
    "# seg-person-dir/\n",
    "#   data/\n",
    "#     annotations/                    # COCOアノテーション\n",
    "#     raw/                            # COCO画像DL先（ゲート通過画像のみ）\n",
    "#       train/\n",
    "#       test/\n",
    "#       val/\n",
    "#     dataset_frontback_yoloseg/      # YOLO形式データセット（出力）\n",
    "#       images/train, val, test/\n",
    "#       labels/train, val, test/\n",
    "#       reports/                      # CSVレポート\n",
    "#       data.yaml\n",
    "\n",
    "\n",
    "dirs_to_create = [\n",
    "    COCO_ANN_DIR,\n",
    "    DATA_RAW / \"train\",\n",
    "    DATA_RAW / \"test\",\n",
    "    DATA_RAW / \"val\",\n",
    "    DATA_OUT / \"images\" / \"train\",\n",
    "    DATA_OUT / \"images\" / \"test\",\n",
    "    DATA_OUT / \"images\" / \"val\",\n",
    "    DATA_OUT / \"labels\" / \"train\",\n",
    "    DATA_OUT / \"labels\" / \"test\",\n",
    "    DATA_OUT / \"labels\" / \"val\",\n",
    "    PROJECT_ROOT / \"runs\",\n",
    "]\n",
    "\n",
    "for d in dirs_to_create:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"OK {d}\")\n",
    "\n",
    "print(\"\\nDirectory structure created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3e3c2c",
   "metadata": {},
   "source": [
    "## 3. COCOアノテーション読み込み → キーポイントフィルタ → Split作成\n",
    "\n",
    "COCOアノテーションから person を含む画像IDを抽出し、**キーポイントゲートで品質フィルタ**した上で split（train/test/val）を作成します。\n",
    "\n",
    "### 手順\n",
    "1. instances + keypoints アノテーションをロード\n",
    "2. person を含む画像IDに対してキーポイントゲート判定（**アノテーション参照のみ**で、画像のダウンロードはまだ不要）\n",
    "3. ゲート通過IDをシャッフルし、`N_TRAIN` / `N_TEST` 分だけ抽出（不足する場合は存在分）\n",
    "4. `val` は `val2017` のゲート通過IDを全数使用\n",
    "\n",
    "### キーポイントゲート条件\n",
    "- 必須：`left_shoulder`(5), `right_shoulder`(6), `left_knee`(13), `right_knee`(14)\n",
    "- 可視性：`v >= 1`（ラベル付き。遮蔽を含む）\n",
    "- 画像内に1人でも条件を満たす歩行者がいれば通過\n",
    "\n",
    "### 前提（必要ファイル）\n",
    "- `data/annotations/instances_train2017.json`\n",
    "- `data/annotations/instances_val2017.json`\n",
    "- `data/annotations/person_keypoints_train2017.json`\n",
    "- `data/annotations/person_keypoints_val2017.json`\n",
    "\n",
    "未取得の場合：\n",
    "```text\n",
    "http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928cd213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# COCOアノテーション読み込み → キーポイントフィルタ → Split作成\n",
    "# ============================================================================\n",
    "from pycocotools.coco import COCO as COCOAPI\n",
    "\n",
    "# ----- 設定 -----\n",
    "N_TRAIN = 20000   # train画像数（フィルタ後）\n",
    "N_TEST  = 3000    # test画像数（フィルタ後）\n",
    "SEED = 42\n",
    "\n",
    "# ----- キーポイントゲート設定 -----\n",
    "# どの部位が見えていれば、フィルタリングを通過とみなすか\n",
    "REQUIRED_KP_INDICES = [5, 6, 13, 14]  # 両肩, 両ひざ\n",
    "# どの程度映っていれば、フィルタリング通過とみなすか（v=0：未ラベル、v=1：ラベル付き（遮蔽含む）, v=2：可視）\n",
    "KP_VIS_THRESHOLD = 1  # v>=1\n",
    "\n",
    "def is_valid_person(ann):\n",
    "    \"\"\"キーポイント条件を満たす歩行者か判定\"\"\"\n",
    "    kps = ann.get(\"keypoints\", None)\n",
    "    if kps is None or len(kps) < 51:\n",
    "        return False\n",
    "    for idx in REQUIRED_KP_INDICES:\n",
    "        if kps[idx * 3 + 2] < KP_VIS_THRESHOLD:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def passes_keypoint_gate(img_id, coco_kp, person_cat_id):\n",
    "    \"\"\"画像レベルゲート: 1人でも全身が映っていれば通過\"\"\"\n",
    "    ann_ids = coco_kp.getAnnIds(imgIds=[img_id], catIds=[person_cat_id], iscrowd=0)\n",
    "    anns = coco_kp.loadAnns(ann_ids)\n",
    "    return any(is_valid_person(a) for a in anns)\n",
    "\n",
    "# ----- アノテーション存在チェック -----\n",
    "assert ANN_TRAIN.exists(), f\"Not found: {ANN_TRAIN}\"\n",
    "assert ANN_VAL.exists(), f\"Not found: {ANN_VAL}\"\n",
    "assert KP_TRAIN.exists(), f\"Not found: {KP_TRAIN}\\nDL: http://images.cocodataset.org/annotations/annotations_trainval2017.zip\"\n",
    "assert KP_VAL.exists(), f\"Not found: {KP_VAL}\"\n",
    "print(f\"OK: {ANN_TRAIN.name}, {ANN_VAL.name}, {KP_TRAIN.name}, {KP_VAL.name}\")\n",
    "\n",
    "# ----- COCOロード -----\n",
    "coco_train = COCOAPI(str(ANN_TRAIN))\n",
    "coco_val   = COCOAPI(str(ANN_VAL))\n",
    "coco_kp_train = COCOAPI(str(KP_TRAIN))\n",
    "coco_kp_val   = COCOAPI(str(KP_VAL))\n",
    "\n",
    "person_id_train = coco_train.getCatIds(catNms=[\"person\"])[0]\n",
    "person_id_val   = coco_val.getCatIds(catNms=[\"person\"])[0]\n",
    "\n",
    "# ----- train2017: 全person画像 → キーポイントフィルタ -----\n",
    "all_person_ids = coco_train.getImgIds(catIds=[person_id_train])\n",
    "print(f\"\\ntrain2017 person images: {len(all_person_ids)}\")\n",
    "\n",
    "clean_person_ids = [\n",
    "    img_id for img_id in all_person_ids\n",
    "    if passes_keypoint_gate(img_id, coco_kp_train, person_id_train)\n",
    "]\n",
    "print(f\"  → gate passed: {len(clean_person_ids)}  (filtered out: {len(all_person_ids) - len(clean_person_ids)})\")\n",
    "\n",
    "# サンプリング（フィルタ後のIDからN_TRAIN + N_TESTを取得）\n",
    "assert len(clean_person_ids) >= N_TRAIN + N_TEST, \\\n",
    "    f\"Not enough clean images: {len(clean_person_ids)} < {N_TRAIN + N_TEST}\"\n",
    "\n",
    "random.seed(SEED)\n",
    "random.shuffle(clean_person_ids)\n",
    "train_ids = clean_person_ids[:N_TRAIN]\n",
    "test_ids  = clean_person_ids[N_TRAIN:N_TRAIN + N_TEST]\n",
    "\n",
    "# ----- val2017: 全person画像 → キーポイントフィルタ -----\n",
    "all_val_person_ids = coco_val.getImgIds(catIds=[person_id_val])\n",
    "print(f\"\\nval2017 person images: {len(all_val_person_ids)}\")\n",
    "\n",
    "val_ids = [\n",
    "    img_id for img_id in all_val_person_ids\n",
    "    if passes_keypoint_gate(img_id, coco_kp_val, person_id_val)\n",
    "]\n",
    "print(f\"  → gate passed: {len(val_ids)}  (filtered out: {len(all_val_person_ids) - len(val_ids)})\")\n",
    "\n",
    "# ----- 結果 -----\n",
    "print(f\"\\nSplit sizes (post-filter):\")\n",
    "print(f\"  train: {len(train_ids)}\")\n",
    "print(f\"  test:  {len(test_ids)}\")\n",
    "print(f\"  val:   {len(val_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50249695",
   "metadata": {},
   "source": [
    "## 4. 画像ダウンロード\n",
    "\n",
    "`coco_url` を使って必要な画像をダウンロードします。\n",
    "\n",
    "- 並列DL（ThreadPoolExecutor）で高速化\n",
    "- 既存ファイルはスキップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16707ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 画像ダウンロード\n",
    "# ============================================================================\n",
    "import urllib.request\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "def download_image(url: str, dest: Path) -> bool:\n",
    "    \"\"\"1枚の画像をダウンロード（既存ならスキップ）\"\"\"\n",
    "    if dest.exists():\n",
    "        return True\n",
    "    try:\n",
    "        urllib.request.urlretrieve(url, dest)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Failed: {url} -> {e}\")\n",
    "        return False\n",
    "\n",
    "def download_images_parallel(coco, img_ids: list, out_dir: Path, max_workers: int = 8):\n",
    "    \"\"\"並列で画像をダウンロード\"\"\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    tasks = []\n",
    "    for img_id in img_ids:\n",
    "        info = coco.loadImgs(img_id)[0]\n",
    "        url = info[\"coco_url\"]\n",
    "        dest = out_dir / info[\"file_name\"]\n",
    "        tasks.append((url, dest))\n",
    "    \n",
    "    success = 0\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(download_image, url, dest): (url, dest) for url, dest in tasks}\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=f\"Download -> {out_dir.name}\"):\n",
    "            if future.result():\n",
    "                success += 1\n",
    "    \n",
    "    print(f\"  {success}/{len(tasks)} downloaded to {out_dir}\")\n",
    "    return success\n",
    "\n",
    "# ----- ダウンロード実行 -----\n",
    "print(\"Downloading train images...\")\n",
    "download_images_parallel(coco_train, train_ids, DATA_RAW / \"train\")\n",
    "\n",
    "print(\"Downloading test images...\")\n",
    "download_images_parallel(coco_train, test_ids, DATA_RAW / \"test\")\n",
    "\n",
    "print(\"Downloading val images...\")\n",
    "download_images_parallel(coco_val, val_ids, DATA_RAW / \"val\")\n",
    "\n",
    "print(\"\\nDownload complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2ad054",
   "metadata": {},
   "source": [
    "## 5. MEBOWモデルのロードと角度推定\n",
    "\n",
    "MEBOWモデルで歩行者cropから向き（角度）を推定し、SAME/OPSクラスに分類します。\n",
    "\n",
    "**前提:** `MEBOW/models/model_hboe.pth` が必要です"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1449b1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MEBOWモデルのロードと角度推定\n",
    "# ============================================================================\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from types import SimpleNamespace\n",
    "\n",
    "# ----- MEBOWパス設定 -----\n",
    "MEBOW_LIB = (MEBOW_ROOT / \"lib\").resolve()\n",
    "if str(MEBOW_LIB) not in sys.path:\n",
    "    sys.path.insert(0, str(MEBOW_LIB))\n",
    "\n",
    "from config import cfg as mebow_cfg\n",
    "from config import update_config as mebow_update_config\n",
    "import models as mebow_models\n",
    "\n",
    "# ----- 前処理 -----\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "mebow_transform = transforms.Compose([transforms.ToTensor(), normalize])\n",
    "\n",
    "def load_mebow_model(\n",
    "    cfg_path=\"experiments/coco/segm-4_lr1e-3.yaml\",\n",
    "    weight_path=\"models/model_hboe.pth\",\n",
    "):\n",
    "    \"\"\"MEBOWモデルをロード\"\"\"\n",
    "    cfg_path = (MEBOW_ROOT / cfg_path).resolve()\n",
    "    weight_path = (MEBOW_ROOT / weight_path).resolve()\n",
    "    \n",
    "    assert weight_path.exists(), f\"MEBOW weight not found: {weight_path}\"\n",
    "    \n",
    "    args = SimpleNamespace(cfg=str(cfg_path), opts=[], modelDir=\"\", logDir=\"\", dataDir=\"\")\n",
    "    mebow_update_config(mebow_cfg, args)\n",
    "    \n",
    "    model = mebow_models.pose_hrnet.get_pose_net(mebow_cfg, is_train=False)\n",
    "    state = torch.load(weight_path, map_location=DEVICE)\n",
    "    if isinstance(state, dict) and \"state_dict\" in state:\n",
    "        state = state[\"state_dict\"]\n",
    "    model.load_state_dict(state, strict=False)\n",
    "    model = model.to(DEVICE).eval()\n",
    "    \n",
    "    width, height = mebow_cfg.MODEL.IMAGE_SIZE\n",
    "    return model, (int(width), int(height))\n",
    "\n",
    "# ----- モデルロード -----\n",
    "mebow_model, MEBOW_INPUT_SIZE = load_mebow_model()\n",
    "print(f\"MEBOW loaded. Input size: {MEBOW_INPUT_SIZE}, Device: {DEVICE}\")\n",
    "\n",
    "@torch.inference_mode()\n",
    "def mebow_predict_angles_from_crops(crops_rgb: list) -> list:\n",
    "    \"\"\"\n",
    "    複数のcrop画像（RGB）から角度を推定\n",
    "    \n",
    "    Args:\n",
    "        crops_rgb: RGB画像のリスト\n",
    "    Returns:\n",
    "        角度のリスト（0-355度、5度刻み）\n",
    "    \"\"\"\n",
    "    if len(crops_rgb) == 0:\n",
    "        return []\n",
    "    \n",
    "    xs = []\n",
    "    for crop in crops_rgb:\n",
    "        crop_rs = cv2.resize(crop, MEBOW_INPUT_SIZE, interpolation=cv2.INTER_LINEAR)\n",
    "        xs.append(mebow_transform(crop_rs))\n",
    "    \n",
    "    x = torch.stack(xs).to(DEVICE)\n",
    "    _, hoe = mebow_model(x)  # (N, 72) - 5度刻み72クラス\n",
    "    idx = torch.argmax(hoe, dim=1)\n",
    "    return (idx * 5).tolist()\n",
    "\n",
    "# ----- クラス分類関数 -----\n",
    "SAME = 0\n",
    "OPS = 1\n",
    "TH_SAME = 45  # same-dirの半幅（0°±45°）\n",
    "\n",
    "def angle_to_class(angle_deg: float) -> int:\n",
    "    \"\"\"\n",
    "    MEBOW角度をSAME/OPSに分類\n",
    "    \n",
    "    - SAME (0): 0°±45° or 360°-45°～360°\n",
    "    - OPS (1): それ以外\n",
    "    \"\"\"\n",
    "    a = angle_deg % 360\n",
    "    if a <= TH_SAME or a >= (360 - TH_SAME):\n",
    "        return SAME\n",
    "    return OPS\n",
    "\n",
    "print(\"angle_to_class defined. (SAME=0, OPS=1, threshold=45deg)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bde9e18",
   "metadata": {},
   "source": [
    "## 6. MEBOW向き推定 + YOLO-Seg変換＆エクスポート\n",
    "\n",
    "ゲート通過済みの画像に対して、MEBOW向き推定とYOLO-Seg形式ラベル生成を行います。\n",
    "\n",
    "**処理内容:**\n",
    "1. 画像を読み込み、全person の bbox を crop（サイズフィルタ: 32x64px以上）\n",
    "2. MEBOW で向き角度を推定 → SAME/OPS クラスに分類\n",
    "3. COCOセグメンテーション → YOLO正規化ポリゴンに変換\n",
    "4. ラベル保存 + 画像コピー\n",
    "5. CSVレポート出力（`reports/{split}_export_report.csv`）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f95deaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MEBOW向き推定 + YOLO-Seg変換 — 関数定義\n",
    "# ============================================================================\n",
    "from pycocotools import mask as coco_mask\n",
    "import csv\n",
    "\n",
    "# 再実行時に過去出力を自動削除\n",
    "REMOVE_STALE_OUTPUTS = True\n",
    "REPORT_DIR = DATA_OUT / \"reports\"\n",
    "\n",
    "# ----- COCO → ポリゴン変換 -----\n",
    "\n",
    "def coco_ann_to_polygons(ann, H, W):\n",
    "    \"\"\"COCOアノテーションからポリゴン座標を抽出\"\"\"\n",
    "    seg = ann.get(\"segmentation\", None)\n",
    "    if seg is None:\n",
    "        return []\n",
    "\n",
    "    if isinstance(seg, list):\n",
    "        polys = []\n",
    "        for s in seg:\n",
    "            pts = np.array(s, dtype=np.float32).reshape(-1, 2)\n",
    "            if len(pts) >= 3:\n",
    "                polys.append(pts)\n",
    "        return polys\n",
    "\n",
    "    if isinstance(seg, dict):\n",
    "        rle = coco_mask.frPyObjects(seg, H, W) if isinstance(seg.get(\"counts\"), list) else seg\n",
    "        m = coco_mask.decode(rle)\n",
    "        if m.ndim == 3:\n",
    "            m = m[:, :, 0]\n",
    "        m = (m > 0).astype(np.uint8) * 255\n",
    "        cnts, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        return [c.reshape(-1, 2).astype(np.float32) for c in cnts if len(c) >= 3]\n",
    "\n",
    "    return []\n",
    "\n",
    "\n",
    "def normalize_poly(poly_xy, H, W):\n",
    "    \"\"\"ポリゴン座標を0-1に正規化\"\"\"\n",
    "    p = poly_xy.copy()\n",
    "    p[:, 0] = np.clip(p[:, 0] / W, 0, 1)\n",
    "    p[:, 1] = np.clip(p[:, 1] / H, 0, 1)\n",
    "    return p\n",
    "\n",
    "\n",
    "# ----- エクスポート関数 -----\n",
    "\n",
    "EXPORT_FIELDS = [\"file_name\", \"img_id\", \"status\", \"reason\", \"n_persons\", \"classes\"]\n",
    "\n",
    "def export_split(split: str, coco, img_dir: Path, img_ids: list, person_cat_id: int):\n",
    "    \"\"\"\n",
    "    ゲート通過済み画像をYOLO-Seg形式でエクスポート\n",
    "\n",
    "    Returns:\n",
    "        records: 各画像の処理結果レコード\n",
    "    \"\"\"\n",
    "    out_images = DATA_OUT / \"images\" / split\n",
    "    out_labels = DATA_OUT / \"labels\" / split\n",
    "    out_images.mkdir(parents=True, exist_ok=True)\n",
    "    out_labels.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def remove_outputs(file_name: str):\n",
    "        if not REMOVE_STALE_OUTPUTS:\n",
    "            return\n",
    "        lbl = out_labels / f\"{Path(file_name).stem}.txt\"\n",
    "        img = out_images / file_name\n",
    "        if lbl.exists(): lbl.unlink()\n",
    "        if img.exists(): img.unlink()\n",
    "\n",
    "    success_count = 0\n",
    "    skip_count = 0\n",
    "    records = []\n",
    "    class_names = {SAME: \"SAME\", OPS: \"OPS\"}\n",
    "\n",
    "    for img_id in tqdm(img_ids, desc=f\"Export {split}\"):\n",
    "        info = coco.loadImgs(img_id)[0]\n",
    "        fn = info[\"file_name\"]\n",
    "        src_img = img_dir / fn\n",
    "\n",
    "        img_bgr = cv2.imread(str(src_img))\n",
    "        if img_bgr is None:\n",
    "            remove_outputs(fn)\n",
    "            skip_count += 1\n",
    "            records.append({\"file_name\": fn, \"img_id\": img_id, \"status\": \"skipped\",\n",
    "                            \"reason\": \"image_not_found\", \"n_persons\": 0, \"classes\": \"\"})\n",
    "            continue\n",
    "\n",
    "        H, W = img_bgr.shape[:2]\n",
    "\n",
    "        # 全person を crop（サイズフィルタ）\n",
    "        ann_ids = coco.getAnnIds(imgIds=[img_id], catIds=[person_cat_id], iscrowd=0)\n",
    "        anns = coco.loadAnns(ann_ids)\n",
    "        crops_rgb, valid_anns = [], []\n",
    "\n",
    "        for ann in anns:\n",
    "            x, y, w, h = ann[\"bbox\"]\n",
    "            if w * h < 32 * 64:\n",
    "                continue\n",
    "            x0, y0 = max(int(x), 0), max(int(y), 0)\n",
    "            x1, y1 = min(int(x + w), W), min(int(y + h), H)\n",
    "            crop = img_bgr[y0:y1, x0:x1]\n",
    "            if crop.size == 0:\n",
    "                continue\n",
    "            crops_rgb.append(crop[:, :, ::-1])\n",
    "            valid_anns.append(ann)\n",
    "\n",
    "        if not crops_rgb:\n",
    "            remove_outputs(fn)\n",
    "            skip_count += 1\n",
    "            records.append({\"file_name\": fn, \"img_id\": img_id, \"status\": \"skipped\",\n",
    "                            \"reason\": \"no_valid_crops\", \"n_persons\": len(anns), \"classes\": \"\"})\n",
    "            continue\n",
    "\n",
    "        # MEBOW角度推定\n",
    "        angles = mebow_predict_angles_from_crops(crops_rgb)\n",
    "\n",
    "        # ラベル生成\n",
    "        lines, line_classes = [], []\n",
    "        for ann, ang in zip(valid_anns, angles):\n",
    "            cls = angle_to_class(ang)\n",
    "            polys = coco_ann_to_polygons(ann, H, W)\n",
    "            if not polys:\n",
    "                continue\n",
    "            poly = max(polys, key=lambda q: abs(cv2.contourArea(q.astype(np.float32))))\n",
    "            eps = 0.002 * (H + W)\n",
    "            poly2 = cv2.approxPolyDP(poly.astype(np.float32), eps, True).reshape(-1, 2)\n",
    "            if len(poly2) < 3:\n",
    "                continue\n",
    "            pn = normalize_poly(poly2, H, W).flatten()\n",
    "            lines.append(str(cls) + \" \" + \" \".join([f\"{v:.6f}\" for v in pn.tolist()]))\n",
    "            line_classes.append(class_names[cls])\n",
    "\n",
    "        if not lines:\n",
    "            remove_outputs(fn)\n",
    "            skip_count += 1\n",
    "            records.append({\"file_name\": fn, \"img_id\": img_id, \"status\": \"skipped\",\n",
    "                            \"reason\": \"no_valid_labels\", \"n_persons\": len(valid_anns), \"classes\": \"\"})\n",
    "            continue\n",
    "\n",
    "        # ラベル保存\n",
    "        label_path = out_labels / f\"{Path(fn).stem}.txt\"\n",
    "        label_path.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
    "\n",
    "        # 画像コピー\n",
    "        dst_img = out_images / fn\n",
    "        if not dst_img.exists():\n",
    "            shutil.copy2(src_img, dst_img)\n",
    "\n",
    "        success_count += 1\n",
    "        records.append({\"file_name\": fn, \"img_id\": img_id, \"status\": \"kept\",\n",
    "                        \"reason\": \"\", \"n_persons\": len(lines), \"classes\": \",\".join(line_classes)})\n",
    "\n",
    "    # CSVレポート保存\n",
    "    REPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    report_path = REPORT_DIR / f\"{split}_export_report.csv\"\n",
    "    with open(report_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=EXPORT_FIELDS)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(records)\n",
    "\n",
    "    print(f\"  {split}: {success_count} kept, {skip_count} skipped  |  Report: {report_path}\")\n",
    "    return records\n",
    "\n",
    "\n",
    "print(\"export_split defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c573521f",
   "metadata": {},
   "source": [
    "## 6.1 エクスポート実行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf87faf2",
   "metadata": {},
   "source": [
    "`export_split()` を `train` / `test` / `val` それぞれに対して実行し、以下を出力します。\n",
    "\n",
    "- 画像：`data/dataset_frontback_yoloseg/images/{split}/`\n",
    "- ラベル：`data/dataset_frontback_yoloseg/labels/{split}/`（YOLO-Seg形式）\n",
    "- レポート：`data/dataset_frontback_yoloseg/reports/{split}_export_report.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e03cbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# エクスポート実行\n",
    "# ============================================================================\n",
    "from collections import Counter\n",
    "\n",
    "print(\"Exporting train...\")\n",
    "train_records = export_split(\"train\", coco_train, DATA_RAW / \"train\", train_ids, person_id_train)\n",
    "\n",
    "print(\"\\nExporting test...\")\n",
    "test_records = export_split(\"test\", coco_train, DATA_RAW / \"test\", test_ids, person_id_train)\n",
    "\n",
    "print(\"\\nExporting val...\")\n",
    "val_records = export_split(\"val\", coco_val, DATA_RAW / \"val\", val_ids, person_id_val)\n",
    "\n",
    "# ----- サマリー -----\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Export Summary\")\n",
    "print(f\"{'='*60}\")\n",
    "for name, recs in [(\"train\", train_records), (\"test\", test_records), (\"val\", val_records)]:\n",
    "    kept = sum(1 for r in recs if r[\"status\"] == \"kept\")\n",
    "    skipped = sum(1 for r in recs if r[\"status\"] == \"skipped\")\n",
    "    print(f\"  {name}: {kept} kept, {skipped} skipped\")\n",
    "\n",
    "print(f\"\\nクラス分布 (person単位):\")\n",
    "for name, recs in [(\"train\", train_records), (\"test\", test_records), (\"val\", val_records)]:\n",
    "    all_cls = []\n",
    "    for r in recs:\n",
    "        if r[\"classes\"]:\n",
    "            all_cls.extend(r[\"classes\"].split(\",\"))\n",
    "    cls_counts = Counter(all_cls)\n",
    "    parts = [f\"{c}:{n}\" for c, n in cls_counts.most_common()]\n",
    "    print(f\"  {name}: {', '.join(parts)}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3b25f1",
   "metadata": {},
   "source": [
    "## 7. data.yaml 生成\n",
    "\n",
    "YOLO学習に必要な設定ファイルを生成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a9ffaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# data.yaml 生成\n",
    "# ============================================================================\n",
    "data_yaml_content = f\"\"\"path: {DATA_OUT.resolve()}\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test\n",
    "names:\n",
    "  0: same-dir-person\n",
    "  1: ops-dir-person\n",
    "\"\"\"\n",
    "\n",
    "data_yaml_path = DATA_OUT / \"data.yaml\"\n",
    "data_yaml_path.write_text(data_yaml_content, encoding=\"utf-8\")\n",
    "\n",
    "print(\"data.yaml created:\")\n",
    "print(\"-\" * 40)\n",
    "print(data_yaml_path.read_text())\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602df31d",
   "metadata": {},
   "source": [
    "## 8. データセット確認\n",
    "\n",
    "生成されたデータセットのファイル数を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec3f18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# データセット確認\n",
    "# ============================================================================\n",
    "print(\"=\" * 50)\n",
    "print(\"Dataset Summary\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for split in [\"train\", \"test\", \"val\"]:\n",
    "    img_dir = DATA_OUT / \"images\" / split\n",
    "    lbl_dir = DATA_OUT / \"labels\" / split\n",
    "\n",
    "    n_img = len(list(img_dir.glob(\"*.jpg\")))\n",
    "    n_lbl = len(list(lbl_dir.glob(\"*.txt\")))\n",
    "\n",
    "    print(f\"  {split:5s}: {n_img:5d} images, {n_lbl:5d} labels\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"data.yaml: {DATA_OUT / 'data.yaml'}\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
